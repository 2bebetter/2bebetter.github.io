<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2bebetter</title>
    <description>to be a better man
</description>
    <link>http://2bebetter.github.io/</link>
    <atom:link href="http://2bebetter.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 28 Oct 2020 21:59:35 +0800</pubDate>
    <lastBuildDate>Wed, 28 Oct 2020 21:59:35 +0800</lastBuildDate>
    <generator>Jekyll v3.1.6</generator>
    
      <item>
        <title>SDN Related Work</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#sdn-related-work&quot; id=&quot;markdown-toc-sdn-related-work&quot;&gt;SDN Related Work&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#sdn-routing&quot; id=&quot;markdown-toc-sdn-routing&quot;&gt;SDN Routing&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#machine-learning&quot; id=&quot;markdown-toc-machine-learning&quot;&gt;Machine Learning&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#cfr-rl-traffic-engineering-with-reinforcement-learning-in-sdn&quot; id=&quot;markdown-toc-cfr-rl-traffic-engineering-with-reinforcement-learning-in-sdn&quot;&gt;CFR-RL: Traffic Engineering With Reinforcement Learning in SDN&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#routenet-leveraging-graph-neural-networks-for-network-modeling-and-optimization-in-sdn&quot; id=&quot;markdown-toc-routenet-leveraging-graph-neural-networks-for-network-modeling-and-optimization-in-sdn&quot;&gt;RouteNet: Leveraging Graph Neural Networks for Network Modeling and Optimization in SDN&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sdn-security&quot; id=&quot;markdown-toc-sdn-security&quot;&gt;SDN Security&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#related-work&quot; id=&quot;markdown-toc-related-work&quot;&gt;Related work&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#bloomstore-dynamic-bloom-filter-based-secure-rule-space-management-scheme-in-sdn&quot; id=&quot;markdown-toc-bloomstore-dynamic-bloom-filter-based-secure-rule-space-management-scheme-in-sdn&quot;&gt;BloomStore: Dynamic Bloom-Filter-based Secure Rule-Space Management Scheme in SDN&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#an-efficient-approach-to-robust-sdn-controller-placement-for-security&quot; id=&quot;markdown-toc-an-efficient-approach-to-robust-sdn-controller-placement-for-security&quot;&gt;An Efficient Approach to Robust SDN Controller Placement for Security&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#load-balancing&quot; id=&quot;markdown-toc-load-balancing&quot;&gt;Load balancing&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#an-energy-efficient-load-distribution-framework-for-sdn-controllers&quot; id=&quot;markdown-toc-an-energy-efficient-load-distribution-framework-for-sdn-controllers&quot;&gt;An energy-efficient load distribution framework for SDN controllers&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#a-trust-management-framework-for-software-defined-network-applications&quot; id=&quot;markdown-toc-a-trust-management-framework-for-software-defined-network-applications&quot;&gt;A trust management framework for software-defined network applications&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#self-healing-and-sdn-bridging-the-gap&quot; id=&quot;markdown-toc-self-healing-and-sdn-bridging-the-gap&quot;&gt;Self-healing and SDN: bridging the gap&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#multi-domain-virtual-network-embedding-with-dynamic-flow-migration-in-software-defined-networks&quot; id=&quot;markdown-toc-multi-domain-virtual-network-embedding-with-dynamic-flow-migration-in-software-defined-networks&quot;&gt;Multi-domain virtual network embedding with dynamic flow migration in software-defined networks&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;sdn-related-work&quot;&gt;SDN Related Work&lt;/h1&gt;

&lt;h2 id=&quot;sdn-routing&quot;&gt;SDN Routing&lt;/h2&gt;

&lt;h3 id=&quot;machine-learning&quot;&gt;Machine Learning&lt;/h3&gt;

&lt;h4 id=&quot;cfr-rl-traffic-engineering-with-reinforcement-learning-in-sdn&quot;&gt;&lt;a href=&quot;https://apps-webofknowledge-com.webvpn.las.ac.cn/full_record.do?product=UA&amp;amp;search_mode=AdvancedSearch&amp;amp;qid=4&amp;amp;SID=6DsnaK11My1YwUPVlix&amp;amp;page=1&amp;amp;doc=4&amp;amp;cacheurlFromRightClick=no&quot;&gt;CFR-RL: Traffic Engineering With Reinforcement Learning in SDN&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;传统的交通工程(TE)解决方案可以通过重新路由尽可能多的流来获得最优或接近最优的性能。然而，当频繁地在网络中重新路由流时，他们通常不会考虑负面影响，比如数据包次序混乱。为了减轻网络干扰的影响，一个有前景的TE解决方案是使用等成本多路径(ECMP)转发大部分流量，并使用软件定义网络(SDN)选择性地重新路由少数关键流量，以平衡网络的链路利用率，其中关键流定义为对网络性能有主要影响的流（例如，最拥塞的链路上的流）。关键流重新路由问题可以分解为两个子问题：（1）识别关键流（2）重新路由它们以实现良好的性能。此外，基于规则的启发式算法不能适应流量矩阵和网络动态的变化，因此不可能基于固定的简单规则来设计该问题的启发式算法。在本文中，我们提出了CFR-RL(临界流重定向-强化学习)，这是一个基于强化学习的方案，它学习一个策略来为每个给定的交通矩阵自动选择临界流。然后，CFR-RL通过制定和解决一个简单的线性规划(LP)问题，重新路由这些选定的关键流，以平衡网络的链路利用率。广泛的评估表明，CFR-RL仅重新路由总流量的10%-21.3%，从而实现接近最佳的性能。&lt;/p&gt;

&lt;h4 id=&quot;routenet-leveraging-graph-neural-networks-for-network-modeling-and-optimization-in-sdn&quot;&gt;&lt;a href=&quot;https://apps-webofknowledge-com.webvpn.las.ac.cn/full_record.do?product=UA&amp;amp;search_mode=AdvancedSearch&amp;amp;qid=4&amp;amp;SID=6DsnaK11My1YwUPVlix&amp;amp;page=1&amp;amp;doc=5&quot;&gt;RouteNet: Leveraging Graph Neural Networks for Network Modeling and Optimization in SDN&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;网络建模是实现自驱动软件定义网络高效运行的关键因素。然而，我们仍然缺乏能够在有限成本下对关键性能指标(KPI)产生准确预测的功能性网络模型，如延迟、抖动或损失。本文提出了一种基于图神经网络(GNN)的新型网络模型RouteNet，该模型能够理解拓扑、路由和输入流量之间的复杂关系，从而准确估计每个源/目的地每个包的时延分布和丢失。RouteNet利用了GNN学习和建模图结构信息，因此，我们的模型能够泛化任意拓扑、路由方案和流量强度。在我们的评估中，我们发现RouteNet能够准确地预测训练中看不到的拓扑、路由和流量的时延分布(平均时延和抖动)和损失(最坏情况MRE = 15.4%)。此外，我们还展示了几个利用我们的GNN模型的KPI预测来实现高效路由优化和网络规划的用例。&lt;/p&gt;

&lt;h2 id=&quot;sdn-security&quot;&gt;SDN Security&lt;/h2&gt;

&lt;h3 id=&quot;related-work&quot;&gt;Related work&lt;/h3&gt;

&lt;h4 id=&quot;bloomstore-dynamic-bloom-filter-based-secure-rule-space-management-scheme-in-sdn&quot;&gt;&lt;a href=&quot;https://apps-webofknowledge-com.webvpn.las.ac.cn/full_record.do?product=UA&amp;amp;search_mode=AdvancedSearch&amp;amp;qid=4&amp;amp;SID=6DsnaK11My1YwUPVlix&amp;amp;page=1&amp;amp;doc=7&amp;amp;cacheurlFromRightClick=no&quot;&gt;BloomStore: Dynamic Bloom-Filter-based Secure Rule-Space Management Scheme in SDN&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;软件定义网络(SDN)通过将复杂和严格的计算任务转移到集中式控制器，提供了一种有效的管理流量负载的方法。它减轻了交换机的负担，交换机的任务是执行基于规则操作对的路由。但是，交换机的流表存储容量有限。它可能不得不面对性能瓶颈，而这又会导致严重的安全漏洞和性能下降。因此，本文提出了SDN中基于动态Bloom-Filter的安全规则空间管理方案BloomStore。BloomStore通过管理网络资源动态地处理数据流量。双重安全检查用于安全数据传输使用双重哈希，即两个独立的哈希函数被用来生成k哈希函数。此外，还提出了分区哈希在bloom数组的bucket中进行插入和查询的方法。结果分析表明，在各种性能参数方面，BloomStore的性能都优于竞争对手的变体。&lt;/p&gt;

&lt;h4 id=&quot;an-efficient-approach-to-robust-sdn-controller-placement-for-security&quot;&gt;&lt;a href=&quot;https://apps-webofknowledge-com.webvpn.las.ac.cn/full_record.do?product=UA&amp;amp;search_mode=AdvancedSearch&amp;amp;qid=4&amp;amp;SID=6DsnaK11My1YwUPVlix&amp;amp;page=1&amp;amp;doc=14&amp;amp;cacheurlFromRightClick=no&quot;&gt;An Efficient Approach to Robust SDN Controller Placement for Security&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;安全是传统网络的关键问题之一。软件定义网络(SDN)通过分离网络的控制平面和数据平面，提高了网络的安全性。为了提高SDN网络的性能，研究人员设计了许多先进的控制器原型，并考虑了控制器的放置问题。然而，链路失效是网络中非常重要的安全问题，极大地影响了SDN网络的安全。在今天，对于链路失败的控制器放置问题仍然是一个挑战。在本文中，我们分别研究了单链路和多链路失效情况下的SDN控制器配置问题。对于单链路故障，我们开发了一种启发式算法来解决控制器配置问题。对于多链路故障，我们引入蒙特卡罗模拟来减少计算开销。我们对真实网络拓扑进行了实验，仿真结果表明启发式算法在取得良好性能的同时，比最优算法节省了更多的时间。&lt;/p&gt;

&lt;h2 id=&quot;load-balancing&quot;&gt;Load balancing&lt;/h2&gt;

&lt;h4 id=&quot;an-energy-efficient-load-distribution-framework-for-sdn-controllers&quot;&gt;&lt;a href=&quot;https://apps-webofknowledge-com.webvpn.las.ac.cn/full_record.do?product=UA&amp;amp;search_mode=AdvancedSearch&amp;amp;qid=4&amp;amp;SID=6DsnaK11My1YwUPVlix&amp;amp;page=1&amp;amp;doc=18&amp;amp;cacheurlFromRightClick=no&quot;&gt;An energy-efficient load distribution framework for SDN controllers&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;软件定义网络(SDN)由于能够根据不同的需求动态配置网络，已经发展成为未来Internet的一个有效平台。我们观察到，随着通信网络的增长，SDN设备的负载和能量需求显著增加。因此，需要对SDN控制器进行高效的建模，平衡负载，优化设备能耗。在本文中，我们提出了一个节能的负荷分配框架和有效的负荷分配和客观上优化网络能耗的流量路由控制器系统模型。该模型通过引入高效节能的路由算法选择过程，实现了基于异构流量需求的负载均衡，降低了能耗。负载均衡方案采用多控制器同步切换迁移技术，而高效路由的新颖之处在于网络设备的休眠和主动模式。为了提高网络的性能，我们提出了负载均衡和节能路由之间的相互作用。大量的仿真结果表明，我们所提出的控制器系统模型的有效性得到了证明，能耗降低了约25%，性能提高了约20%。该模型适用于满足绿色通信标准的现实网络环境。&lt;/p&gt;

&lt;h4 id=&quot;a-trust-management-framework-for-software-defined-network-applications&quot;&gt;&lt;a href=&quot;https://apps-webofknowledge-com.webvpn.las.ac.cn/full_record.do?product=UA&amp;amp;search_mode=AdvancedSearch&amp;amp;qid=4&amp;amp;SID=6DsnaK11My1YwUPVlix&amp;amp;page=1&amp;amp;doc=22&quot;&gt;A trust management framework for software-defined network applications&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;(评估框架)&lt;/p&gt;

&lt;p&gt;SDN (software-defined network, SDN)的出现给现有网络带来了前所未有的创新。SDN的两个最显著的特性是解耦性和可编程性。解耦使得网络管理集中在一个控制平面上。同时，得益于SDN的可编程特性，可以很容易地实现新的组网功能。然而，这些特性也给SDN带来了新的安全问题。通过SDN提供的编程接口，软件工程师可以轻松开发网络应用程序，生成SDN控制平面的组网策略，以指导网络路由。然而，这些新应用的安全性和质量很难保证。恶意或低质量的应用程序可能会破坏整个网络。为了解决这个问题，本文提出了一种新的SDN应用信任管理框架。它可以根据应用程序对网络性能(如时延、丢包率、吞吐量等)的影响来评估应用程序的信任值。这些信任值对SDN中应用程序的管理和选择起到了决定性的作用。我们通过一个基于泛光灯控制器的原型系统来评估该框架的性能。实验结果表明了设计的正确性和有效性。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://apps-webofknowledge-com.webvpn.las.ac.cn/full_record.do?product=UA&amp;amp;search_mode=AdvancedSearch&amp;amp;qid=4&amp;amp;SID=6DsnaK11My1YwUPVlix&amp;amp;page=1&amp;amp;doc=23&quot;&gt;ArchSDN: a reinforcement learning-based autonomous OpenFlow controller with distributed management properties&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;网络控制器的屏蔽能力对网络运营商有信心继续扩展通信网络至关重要。今天的网络可以使用该软件定义网络(SDN)概念分离控制和转换层面，并使用自主自治特性快速应对任何网络活动,同时为网络提供必要的灵活性,支持自定义服务级别协议(SLA)的客户,同时降低资本和运营开支。SDN和自主管理的概念都有一个集中式的架构，需要一个单一的实体管理网络的方方面面，这使得在庞大的物联网世界中管理整个网络变得困难，在这些网络中服务往往是靠近用户，基于边缘的方法是支持5G和超越服务的关键。要支持这种动态和灵活的网络，需要一种方法，通过多个自主的OpenFlow控制器(我们称之为ArchSDN控制器)来分配网络管理职责。通过将OpenFlow交换机分配给不同的ArchSDN控制器，将网络划分为不同的扇区，每个扇区由一个ArchSDN控制器独占控制。这些控制者协调他们的行动，并使用基于强化学习的决策机制来探索、学习和实现接近最佳的端到端通信路径。评估结果表明，所提出的决策系统能够找到接近最优的解决方案，从已获得的结果中学习以改进未来的服务激活结果，并能在不到100毫秒的时间内响应，使网络快速适应通信链路的丢失。&lt;/p&gt;

&lt;h4 id=&quot;self-healing-and-sdn-bridging-the-gap&quot;&gt;&lt;a href=&quot;https://apps-webofknowledge-com.webvpn.las.ac.cn/full_record.do?product=UA&amp;amp;search_mode=AdvancedSearch&amp;amp;qid=4&amp;amp;SID=6DsnaK11My1YwUPVlix&amp;amp;page=1&amp;amp;doc=27&amp;amp;cacheurlFromRightClick=no&quot;&gt;Self-healing and SDN: bridging the gap&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;随着分布式交互应用的普及，为了获得良好的参与者交互体验，必须考虑网络资源的高效和公平分配。在软件定义的网络中，中央控制器的存在为交互式应用程序部署可定制的路由提供了一种新颖的解决方案，它允许对DIAs进行细粒度的资源分配，以实现参与者之间的公平性。但是机遇总是伴随着挑战，广泛分布的用户位置往往需要分配控制器来满足应用的要求。因此，参与者之间的延迟直接受到控制器处理时间的影响。在此背景下，我们解决了DIAs在计算和链路负载方面的公平资源配置问题，目的是平衡SDN网络中多流之间的可实现请求率和公平性。首先，我们将问题表示为控制器加载和路由优化的组合。然后，提出了基于深度学习的主动分配控制器算法和公平路径分配算法来共享瓶颈环节。与目前最先进的贪婪分配算法和优先级分配算法相比，通过跟踪驱动仿真验证了该算法在控制器和链路负载方面具有更好的公平性。&lt;/p&gt;

&lt;h4 id=&quot;multi-domain-virtual-network-embedding-with-dynamic-flow-migration-in-software-defined-networks&quot;&gt;&lt;a href=&quot;https://apps-webofknowledge-com.webvpn.las.ac.cn/full_record.do?product=UA&amp;amp;search_mode=AdvancedSearch&amp;amp;qid=3&amp;amp;SID=5FUOQZPzuNrS9dmyBmq&amp;amp;page=1&amp;amp;doc=34&amp;amp;cacheurlFromRightClick=no&quot;&gt;Multi-domain virtual network embedding with dynamic flow migration in software-defined networks&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;软件定义网络(SDN)解耦了网络的控制面和数据面，并使用一个中央控制器来提供有效使用网络资源和方便的服务提供。SDN中的虚拟化使虚拟SDN网络能够共享公共的物理网络基础设施，从而使它们能够提供通用的服务。在这种设置下，SDN hypervisor支持多个虚拟SDN网络(vSDN)，其中每个vSDN网络都有自己的控制器。为了建立虚拟网络，实现物理网络资源的优化共享，设计了虚拟网络嵌入算法。单域虚拟虚拟机是虚拟虚拟机研究的一个热点问题。然而，在大多数实际场景中，VNs是跨属于不同基础设施提供者(InPs)的异构管理域供应的。&lt;/p&gt;

&lt;p&gt;本文利用不规则细胞学习自动机(ICLA)提出了一种用于多域SDN网络的VNE算法，即vSDN-CLA。我们考虑了两个方面——虚拟节点和链路在多域基片网络中的最优映射，以及SDN控制器在吞吐量和端到端延迟方面的最优配置。我们通过考虑动态流迁移来扩展vSDN-CLA，以实现资源最优路由。我们使用Mininet评估了提议的方案，我们观察到提议的方案在吞吐量、端到端延迟和虚拟网络请求接受率方面优于现有的基准方案在单域和多域环境下。&lt;/p&gt;
</description>
        <pubDate>Tue, 27 Oct 2020 12:51:40 +0800</pubDate>
        <link>http://2bebetter.github.io/thesis/2020/10/27/SDN-related-work/</link>
        <guid isPermaLink="true">http://2bebetter.github.io/thesis/2020/10/27/SDN-related-work/</guid>
        
        
        <category>thesis</category>
        
      </item>
    
      <item>
        <title>Edge Cloud Network</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#edge-cloud-network&quot; id=&quot;markdown-toc-edge-cloud-network&quot;&gt;Edge Cloud Network&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#definition&quot; id=&quot;markdown-toc-definition&quot;&gt;Definition&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#benefits&quot; id=&quot;markdown-toc-benefits&quot;&gt;Benefits&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#related-work&quot; id=&quot;markdown-toc-related-work&quot;&gt;Related work&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#a-novel-load-balancing-and-low-response-delay-framework-for-edge-cloud-network-based-on-sdn&quot; id=&quot;markdown-toc-a-novel-load-balancing-and-low-response-delay-framework-for-edge-cloud-network-based-on-sdn&quot;&gt;A Novel Load Balancing and Low Response Delay Framework for Edge-Cloud Network Based on SDN&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#optimal-vnf-placement-via-deep-reinforcement-learning-in-sdnnfv-enabled-networks&quot; id=&quot;markdown-toc-optimal-vnf-placement-via-deep-reinforcement-learning-in-sdnnfv-enabled-networks&quot;&gt;Optimal VNF Placement via Deep Reinforcement Learning in SDN/NFV-Enabled Networks&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#an-optimal-delay-aware-task-assignment-scheme-for-wireless-sdn-networked-edge-cloudlets&quot; id=&quot;markdown-toc-an-optimal-delay-aware-task-assignment-scheme-for-wireless-sdn-networked-edge-cloudlets&quot;&gt;An optimal delay aware task assignment scheme for wireless SDN networked edge cloudlets&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;edge-cloud-network&quot;&gt;Edge Cloud Network&lt;/h1&gt;

&lt;h2 id=&quot;definition&quot;&gt;Definition&lt;/h2&gt;

&lt;p&gt;边缘云架构用于将权力分散(处理)到网络的边缘(客户端/设备)。传统服务器的计算能力用于执行数据最小化或创建先进的分布式系统等任务。在云模型中，这样的“智能”任务由服务器执行，因此它们可以被转移到其他计算能力较低或几乎没有计算能力的设备上。&lt;/p&gt;

&lt;p&gt;有了边缘云，这些处理任务的很大一部分都被转移到了客户端，这也被称为边缘计算(Edge Computing)。边缘计算通常指物联网(IOT)设备，但也指在设备上处理遥测数据(而不是将原始数据发送到云)的游戏硬件。&lt;/p&gt;

&lt;p&gt;这为企业创造了很多机会，特别是当他们希望在整个应用程序或高密度平台使用中提供低延迟服务时。&lt;/p&gt;

&lt;h2 id=&quot;benefits&quot;&gt;Benefits&lt;/h2&gt;

&lt;p&gt;相较于传统的客户机连接到服务器的模型，边缘云架构中数以千计的客户机相互连接可以更加快速有效地执行较小的处理任务。理想的边缘计算环境使数以百万计的物联网设备形成一个庞大的智能网络，可以执行通常只有在非常大的数据中心才可能执行的任务。&lt;/p&gt;

&lt;p&gt;通过结合Edge和Cloud，我们可以利用分布式系统的力量，在设备上处理数据，然后将数据发送到云中。在这里，可以使用更少(甚至不可用)的处理能力来处理、分析或保存它。&lt;/p&gt;

&lt;p&gt;例如：得益于Edge云架构，共享信息的联网汽车能够自己分析数据，而不用使用服务器的处理能力。与需要在中央服务器上处理的大量数据回程不同，大部分处理工作已经由连接的设备自己完成了。&lt;/p&gt;

&lt;p&gt;边缘云的好处还有很多，包括以服务提供商的身份有效部署新服务，或为联网汽车司机或在线游戏玩家提供低延迟体验。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Contrail Edge Cloud等解决方案将计算、存储和网络资源在基站、集线器、交换站点和中央办公室等轻量级边缘环境中抽象和虚拟化。&lt;/li&gt;
  &lt;li&gt;通过低延迟、自动化和简单的交付，边缘云架构在不牺牲多租户安全云的丰富功能的情况下，加速了网络边缘的服务创建。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;related-work&quot;&gt;Related work&lt;/h2&gt;

&lt;h3 id=&quot;a-novel-load-balancing-and-low-response-delay-framework-for-edge-cloud-network-based-on-sdn&quot;&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/document/8892518&quot;&gt;A Novel Load Balancing and Low Response Delay Framework for Edge-Cloud Network Based on SDN&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;基于软件定义网络(SDNs)的云计算，需要收集更多的数据到云中进行分析，由于互联网容量有限，这会导致更多的冗余数据和更长的服务响应时间。针对这一问题，提出了一种新的服务编排与数据聚合框架(SODA)，该框架将数据编排为服务，并对数据包进行聚合，以减少数据冗余和服务响应延迟。在SODA中，网络被分为三层。1)数据中心层(DCL)。数据中心(DCs)向网络中的所有设备发布具有特定功能的软件，设备将数据编配为服务，并使用软件聚合数据包以减少服务响应延迟。2)中间路由层(MRL)。根据数据包与路由距离的相关性调整该层数据包的路由路径。数据包相关性越高，路由距离越短，为了减少冗余数据，数据包沿同一路由路径传输的概率就越高。3)车辆网络层(VNL)。移动车辆用于在设备之间传输数据包和服务。进行了一系列的实验和仿真。结果表明，与传统方案相比，该方案具有更好的性能。&lt;/p&gt;

&lt;h3 id=&quot;optimal-vnf-placement-via-deep-reinforcement-learning-in-sdnnfv-enabled-networks&quot;&gt;&lt;a href=&quot;https://apps-webofknowledge-com.webvpn.las.ac.cn/full_record.do?product=UA&amp;amp;search_mode=AdvancedSearch&amp;amp;qid=8&amp;amp;SID=7Fz7cFld277jLHIz9RY&amp;amp;page=1&amp;amp;doc=30&amp;amp;cacheurlFromRightClick=no&quot;&gt;Optimal VNF Placement via Deep Reinforcement Learning in SDN/NFV-Enabled Networks&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;新兴的范式——软件定义网络(SDN)和网络功能虚拟化(NFV)——使得在商用设备上运行虚拟网络功能(VNFs)变得可行且可伸缩，从而以更低的成本提供各种网络服务。得益于集中的网络管理，可以在支持SDN/ nfv的网络中收集关于网络设备、流量和资源的大量信息，根据收集到的信息利用机器学习定制算法，有效优化网络性能。本文研究了SDN/ nfv支持的网络中的VNF布局问题，它可以自然地表述为二进制整数规划(BIP)问题。利用深度强化学习，提出了一种基于双深度Q网络的VNF布局算法(DDQN-VNFPA)。具体来说，DDQN从一个巨大的解决方案空间确定最佳解决方案，然后DDQN- vnfpa按照基于阈值的策略放置VNF实例(VNFIs)。我们在一个真实的网络拓扑中通过跟踪驱动模拟来评估DDQN-VNFPA。评估结果表明，与已有文献中的算法相比，DDQN-VNFPA在业务功能链请求的拒绝数和拒绝率、吞吐量、端到端延迟、VNFI运行时间和负载均衡等方面均有较好的网络性能。&lt;/p&gt;

&lt;h3 id=&quot;an-optimal-delay-aware-task-assignment-scheme-for-wireless-sdn-networked-edge-cloudlets&quot;&gt;&lt;a href=&quot;https://apps-webofknowledge-com.webvpn.las.ac.cn/full_record.do?product=UA&amp;amp;search_mode=AdvancedSearch&amp;amp;qid=8&amp;amp;SID=7Fz7cFld277jLHIz9RY&amp;amp;page=1&amp;amp;doc=31&quot;&gt;An optimal delay aware task assignment scheme for wireless SDN networked edge cloudlets&lt;/a&gt;&lt;/h3&gt;

</description>
        <pubDate>Mon, 26 Oct 2020 12:51:40 +0800</pubDate>
        <link>http://2bebetter.github.io/thesis/2020/10/26/edge-cloud-network/</link>
        <guid isPermaLink="true">http://2bebetter.github.io/thesis/2020/10/26/edge-cloud-network/</guid>
        
        
        <category>thesis</category>
        
      </item>
    
      <item>
        <title>Recent Advances of Resource Allocation in Network Function Virtualization</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot; id=&quot;markdown-toc-introduction&quot;&gt;introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#preliminary&quot; id=&quot;markdown-toc-preliminary&quot;&gt;Preliminary&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#basic-problem-definition-and-analysis&quot; id=&quot;markdown-toc-basic-problem-definition-and-analysis&quot;&gt;Basic Problem Definition and Analysis&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#examples&quot; id=&quot;markdown-toc-examples&quot;&gt;examples&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-goals&quot; id=&quot;markdown-toc-problem-goals&quot;&gt;Problem Goals&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-formulation&quot; id=&quot;markdown-toc-problem-formulation&quot;&gt;Problem Formulation&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mainly-adopted-approaches&quot; id=&quot;markdown-toc-mainly-adopted-approaches&quot;&gt;Mainly Adopted Approaches&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#qos-models-in-nfv&quot; id=&quot;markdown-toc-qos-models-in-nfv&quot;&gt;QoS Models in NFV&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#delay-calculation-of-an-sfc&quot; id=&quot;markdown-toc-delay-calculation-of-an-sfc&quot;&gt;Delay Calculation of an SFC&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#nfv-resilience&quot; id=&quot;markdown-toc-nfv-resilience&quot;&gt;NFV Resilience&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resource-allocation-in-nfv&quot; id=&quot;markdown-toc-resource-allocation-in-nfv&quot;&gt;Resource Allocation in NFV&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#cost-aware-resource-allocation&quot; id=&quot;markdown-toc-cost-aware-resource-allocation&quot;&gt;Cost-Aware Resource Allocation&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#vptr-problem&quot; id=&quot;markdown-toc-vptr-problem&quot;&gt;VPTR Problem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#vnfp-problem&quot; id=&quot;markdown-toc-vnfp-problem&quot;&gt;VNFP Problem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#trr-problem&quot; id=&quot;markdown-toc-trr-problem&quot;&gt;TRR Problem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#vrc-problem&quot; id=&quot;markdown-toc-vrc-problem&quot;&gt;VRC Problem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#discussion&quot; id=&quot;markdown-toc-discussion&quot;&gt;Discussion&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#delay-aware-resource-allocation&quot; id=&quot;markdown-toc-delay-aware-resource-allocation&quot;&gt;Delay-Aware Resource Allocation&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#vptr-and-trr-problem&quot; id=&quot;markdown-toc-vptr-and-trr-problem&quot;&gt;VPTR and TRR Problem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#vnfp-problem-1&quot; id=&quot;markdown-toc-vnfp-problem-1&quot;&gt;VNFP Problem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#discussion-1&quot; id=&quot;markdown-toc-discussion-1&quot;&gt;Discussion&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#availabilityresilience-aware-resource-allocation&quot; id=&quot;markdown-toc-availabilityresilience-aware-resource-allocation&quot;&gt;Availability/Resilience-Aware Resource Allocation&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#vptr-problem-1&quot; id=&quot;markdown-toc-vptr-problem-1&quot;&gt;VPTR Problem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#vnfp-problem-2&quot; id=&quot;markdown-toc-vnfp-problem-2&quot;&gt;VNFP Problem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#trr-problem-1&quot; id=&quot;markdown-toc-trr-problem-1&quot;&gt;TRR Problem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#discussion-2&quot; id=&quot;markdown-toc-discussion-2&quot;&gt;Discussion&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#energy-efficient-resource-allocation&quot; id=&quot;markdown-toc-energy-efficient-resource-allocation&quot;&gt;Energy-Efficient Resource Allocation&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#vptr-problem-2&quot; id=&quot;markdown-toc-vptr-problem-2&quot;&gt;VPTR Problem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#vrc-problem-1&quot; id=&quot;markdown-toc-vrc-problem-1&quot;&gt;VRC Problem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#discussion-3&quot; id=&quot;markdown-toc-discussion-3&quot;&gt;Discussion&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#multi-objective-resource-allocation-in-edge-cloud&quot; id=&quot;markdown-toc-multi-objective-resource-allocation-in-edge-cloud&quot;&gt;(Multi-Objective) Resource Allocation in Edge Cloud&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#vptr-problem-3&quot; id=&quot;markdown-toc-vptr-problem-3&quot;&gt;VPTR Problem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#vnfp-problem-3&quot; id=&quot;markdown-toc-vnfp-problem-3&quot;&gt;VNFP Problem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#discussion-4&quot; id=&quot;markdown-toc-discussion-4&quot;&gt;Discussion&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#on-line-provisioning-for-nfv&quot; id=&quot;markdown-toc-on-line-provisioning-for-nfv&quot;&gt;On-Line Provisioning for NFV&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#prediction-based-online-scheduling&quot; id=&quot;markdown-toc-prediction-based-online-scheduling&quot;&gt;Prediction-Based Online Scheduling&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#regularization-based-online-scheduling&quot; id=&quot;markdown-toc-regularization-based-online-scheduling&quot;&gt;Regularization-Based Online Scheduling&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#emerging-topics-and-future-works&quot; id=&quot;markdown-toc-emerging-topics-and-future-works&quot;&gt;Emerging Topics and Future Works&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#machine-learning-based-approaches&quot; id=&quot;markdown-toc-machine-learning-based-approaches&quot;&gt;Machine Learning-Based Approaches&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;introduction&lt;/h2&gt;

&lt;p&gt;随着新的服务模式(如云计算或虚拟现实)的不断出现，以及对网络服务(如高维视频)的服务质量(QoS)要求越来越高，网络上的IP流量呈指数级增长。根据思科[1]的预测，到2021年全球IP流量将达到3.3 ZB，自2016年以来复合年增长率(CAGR)为24%。在传统的网络服务供应范式中，网络功能(如防火墙或负载均衡器)也称为中间件，通常由专用硬件设备实现。由于设计和生产成本较高，部署硬件中间件的成本很高，而且这些中间件需要手动配置和管理，这进一步增加了服务提供商的成本。因此，从资本支出(CAPEX)和运营支出(OPEX)来看，传统的网络服务模式无法满足不断增长的用户QoS要求，这给网络服务提供商带来了很大的挑战。&lt;/p&gt;

&lt;p&gt;网络功能虚拟化(NFV)最初是由欧洲电信标准协会(ETSI)[2]在2012年提出的，现在已经成为一种很有吸引力的解决方案，因为它可以用在虚拟化环境中运行的软件实例来替代专用的硬件设备。在NFV中，所请求的服务由一系列虚拟网络功能(VNF)实现，这些功能可以利用虚拟化技术在通用服务器上运行。这些VNFs按照预定义的顺序排列，数据流通过这些顺序进行遍历，它也称为服务功能链(SFC)。得益于虚拟化技术，可以通过将请求的VNFs以非常高效和敏捷的方式放在网络上来建立SFC。此外，可以以非常低的成本和高效率动态地添加或删除一个或多个VNFs，以应对更改了所请求的SFCs的情况。NFV允许以更可伸缩和弹性的方式分配网络资源，为网络功能提供更高效和灵活的管理和运行机制，从而可以显著降低网络服务提供商的资本支出和运营支出。&lt;/p&gt;

&lt;p&gt;一个重要的问题是我们如何有效地分配网络资源来建立所要求的服务功能链，它主要处理(基本的)VNF放置和流量路由(VPTR)问题及其变体，即将每个用户请求的VNFs放在网络上，在不破坏节点容量和链路带宽的情况下在每个邻近的VNF对之间找到路由。由于NFV的固有特性和设计原则，VPTR问题不同于现有的服务放置和路由问题，虚拟机放置和路由问题。例如，当请求的VNFs被放在网络上时，路由应该按照预定义的顺序逐个遍历每个定位的VNF。此外，在VPTR问题中还需要考虑QoS参数。例如，在一个SFC中，在这个链接中遍历每个VNF的数据包的端到端延迟是衡量NFV性能的重要QoS。为了保证用户满意的网络服务，服务提供商需要向用户承诺对延迟敏感的性能和服务。弹性是NFV的另一个重要的QoS参数，它定义了所提供的服务在面对失败时的生存水平。因为，一旦SFC的一个节点或一个链接出现故障，整个SFC就无法运作，因此所提供的服务就必须停止。当考虑这些QoS参数时，VPTR问题及其变体就变得更加复杂。因此，从不同维度深入了解NFV的资源配置问题是非常重要的，这也是本次调查的重点。&lt;/p&gt;

&lt;p&gt;该篇论文并没有像其它调查一样，从NFV架构和实现、NFV中的资源分配以及它在其它领域中的应用方面提供一个广泛观点，而是针对一个专门的主题：回顾NFV中关于资源分配的最新工作。同时为了简洁，并没有该问题进一步划分。本次调查所回顾的大部分工作在之前的调查工作中都没有涉及到，因此本次调查可以看作是对这些工作的延伸和发展。除此之外，本文还介绍了相关问题的定义和分析，以及相应的解决方法和应用技术，以及主要采用的QoS模型。我们的目的是提供一个详细的回顾，以总结最近的发展和有趣的突破，以解决在NFV中有关的资源配置问题。&lt;/p&gt;

&lt;p&gt;这篇文章的内容组织如下：首先概括和总结了NFV中四个具有代表性的资源分配问题，并分析了它们的特点和复杂性；第3节介绍了NFV资源分配中的时延和可靠性参数的QoS模型。并特别提出一个一般可用性计算模型来定量计算SFC保护的可用性。第4节总结了现有文献，根据不同的QoS参数(如成本、延迟、可靠性、能量)和不同的场景(如边缘云、在线供应、分布式供应)进行分类。第5节讨论一些新出现的主题并指出一些可能的方向。最后，第6节对调查进行了总结。&lt;/p&gt;

&lt;h2 id=&quot;preliminary&quot;&gt;Preliminary&lt;/h2&gt;

&lt;h3 id=&quot;basic-problem-definition-and-analysis&quot;&gt;Basic Problem Definition and Analysis&lt;/h3&gt;

&lt;p&gt;一个网络可以被表示为G(N, L)，N个节点和L个连接。我们用R代表请求集合,一个请求α的集合R(α,F, w)∈R,α表示请求的数据率(所需带宽),F表示有序的VNFs集合,和w= (w1 w2,…,wm)是一个有m个请求的向量(例如,成本、延迟、可用性、能量,等等)。一个VNF f∈F在节点n∈Ψfn所需要的处理时间表示数据包的到达节点n的功能f的处理延迟。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;定义一：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In a given network G(N,L) and for each request r(α,F,w⃗ )∈R, the VNF Placement and Traffic Routing (VPTR) problem is to place its requested VNFs on N and find routes among each adjacent VNF pair without violating the node capacity and link bandwidth such that the requirement vector w is satisfied.&lt;/p&gt;

&lt;p&gt;给定网络G和请求r，VNF的放置和VPTR问题就是讲请求的VNFs放置在N节点上并且为每一对相邻VNF在不违反节点容量和满足链路带宽的需求向量w的情况下找到路由&lt;/p&gt;

&lt;p&gt;VNF布局(VNFP)问题，不考虑流量路由(sub)问题，定义如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;定义二：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For a network G(N,L) and a set of requests R, suppose that the path between any node pair in the network is known/given, and each adjacent VNF pair chooses the given path to route the traffic. For each request r(α,F,w)∈R, the VNF Placement (VNFP) problem is to place its requested VNFs on N without violating the node capacity such that w is satisfied.&lt;/p&gt;

&lt;p&gt;对于给定的网络G和请求集合R，假设任意一对节点之间的路径是已知的，并且每一对相邻VNF都会选择给定的路径去转发流量。对于每一个请求r，VNFP问题就是将它请求的VNFs在不超过节点容量和满足向量w的情况下放置在N上&lt;/p&gt;

&lt;p&gt;当请求的VNFs已经被放到网络上时，VPTR问题变成了流量路由(TRR)问题，其定义如下:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;定义三：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In a given network G(N,L) where a set of existing SFCs are already deployed in the network, the VNF Redeployment and Consolidation (VRC) problem is to redeploy the already existing SFCs such that the requirement vector w is satisfied.&lt;/p&gt;

&lt;p&gt;在给定网络G (N, L)，一组现有的SFCs已经部署在网络中，VNF调动和整合(VRC)问题是重新部署现有SFCs以满足要求向量w。值得注意的是，在虚拟网络嵌入(VNE)[14]问题中，虚拟网络请求(VNR)由一组所需的虚拟节点和虚拟链接组成。VNE问题是将每个VNR映射到基底(物理)网络，以便每个虚拟节点被放置在具有足够容量的不同基底节点上，并为每个虚拟链路分配一条具有足够带宽的路径。虽然VNE问题与VPTR问题有一些相似之处，但有以下不同之处:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;在VPTR问题中，SFC中所需的VNFs有一个预定义的顺序，流量必须遍历这个顺序下的每个VNF。相反，在VNE问题中，请求的虚拟节点之间没有必要的顺序。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以在VPTR问题的一个节点中放置一个或多个所需的VNFs，但是，VNE问题中的每个请求的虚拟节点必须映射到不同的物理节点上。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在流量经过一个VNF进行处理后，它的速率可能在VPTR问题中发生改变(增加或减少)。然而，在VNE问题中，不同虚拟节点对之间的流量率基本保持不变&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;在线和离线配置&lt;/em&gt;。通常,在离线配置方案中,R是事先给定的,我们的目标是基于R设计最优解。相反，在在线配置方案中，假设R中的请求以在线的方式到达网络，我们必须处理一个接一个的请求，因为我们没办法获知未来的请求。除非另有说明，在本次调查中默认采用离线供应方案。在4.6节中，该论文将会讨论NFV中用于在线供应方案的资源分配问题。&lt;/p&gt;

&lt;h3 id=&quot;examples&quot;&gt;examples&lt;/h3&gt;

&lt;p&gt;使用下图中的一个例子来描述VPTR问题。图1中的网络有5个节点(包括进入节点和出口节点)，节点a、节点b、节点c的容量分别为8、11、15。链接的容量在链接上方显示。假设一个请求r请求一个SFC，顺序是f1−f2−f3−f4，该订单由4个VNFs组成，其资源需求分别为8、6、14和5。我们必须像网络中所示的那样将这些VNFs放在节点上，而不破坏节点的容量。对于r，让α =5 Mb/s，则该SFC中的整个路由是：进入→a→b→c→b→出口，且不破坏每个遍历链路的容量。我们注意到，这个路由并不是简单路径，因为它包含一个循环。从这个例子中，我们可以看到，遍历整个SFC的路由不一定是简单的路径，这使得VPTR问题更加复杂。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2020-10-21-thesis-reading-01/yang1-3017001-small.gif&quot; alt=&quot;yang1-3017001-small&quot; /&gt;&lt;/p&gt;

&lt;p&gt;接下来从一个示例开始说明VRC问题。假设有2个请求，其中r1请求的SFC为f1 - f3, r2请求的SFC为f1 - f2。在图中，原本放置在a、b和c上的f1、f2和f3为这两个请求提供服务。经过整合和重新部署，f3从c迁移到b，我们关闭了c&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2020-10-21-thesis-reading-01/yang2-3017001-small.gif&quot; alt=&quot;yang2-3017001-small&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;problem-goals&quot;&gt;Problem Goals&lt;/h3&gt;

&lt;p&gt;到目前为止，我们在2.1节中正式定义了VPTR问题及其变体，并在2.2节中通过示例描述了这些问题。然而，我们没有提到这些问题的问题目标。例如，除了为VPTR问题找到可行的VNF布局和路由解决方案之外，要实现的问题目标是什么?我们可以将问题目标理解为优化问题的目标函数。以下是经常使用的问题目标:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Maximum link utilization (MLU)&lt;/em&gt;：其链接利用率(ul)被定义为$ v (l) \div c (l) $ ，其中v (l)表示的l中的实际穿越流，c (l)表明l的总容量。一个网络的最大链路利用率是其所有链路的最大链路利用率。目标是使MLU最小化。有时，也使用MLU的倒数，这被称为网络吞吐量，在这些情况下，最大化网络吞吐量相当于最小化MLU。&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;QoS parameters&lt;/em&gt;：QoS的主要参数包括服务时延、可用性、能耗等。这些参数可以定量地反映NFV服务提供给客户的程度。&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Costs and Revenue&lt;/em&gt;：主要用于网络运营商，它表示在节点上部署VNFs和在使用的链接之间路由流量的操作支出。而收入则是指在容量约束条件下，通过满足流量需求而获得的净收益。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;problem-formulation&quot;&gt;Problem Formulation&lt;/h3&gt;

&lt;p&gt;在本节中，我们将全有序SFC中的(基本)VPTR问题2表示为整数非线性规划[16]。我们从一些必要的符号和变量开始:&lt;/p&gt;

&lt;p&gt;$f_i$和$f_j$:SFC中连续两个VNFs。&lt;/p&gt;

&lt;p&gt;$X^{f,r}_n$ ：一个布尔变量，如果请求r的VNF f放在节点n∈n上，则返回1，否则返回0&lt;/p&gt;

&lt;p&gt;$Y_{f_i,f_j,r}^{(u,v)}$ ：一个布尔变量，如果请求r的VNFs fi和fj之间的流遍历link (u,v)，则返回1，否则返回0。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{equation*} \sum _{(u,v) \in \mathcal {L}} Y_{f_i,f_j,r}^{(u,v)}=1 ~~ v \in \mathcal {N}: X^{f_j,r}_v=1 \&amp;\&amp; X^{f_i,r}_v \ne 1, r \in R \quad\quad \tag{2} \end{equation*} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;em&gt;Placement Constraint.&lt;/em&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation*} \sum _{n \in \mathcal {N}} X^{f,r}_n = 1~~ \forall r \in R, f \in r. \tag{4} \end{equation*}&lt;/script&gt;

&lt;p&gt;&lt;em&gt;Link Capacity Constraint.&lt;/em&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation*} \sum _{r(\alpha, F, \vec{w}) \in R, (f_i,f_j) \in r} Y_{f_i,f_j,r}^{(u,v)} \cdot \alpha \leq c(u,v)~~\forall (u,v) \in \mathcal {L}. \tag{5} \end{equation*}&lt;/script&gt;

&lt;p&gt;&lt;em&gt;Node Processing Capacity Constraint.&lt;/em&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation*} \sum _{r(\alpha, F, \vec{w}) \in R, f \in r} X^{f,r}_n \cdot \eta (f) \leq \pi (n) ~~ \forall n \in \mathcal {N}. \tag{6} \end{equation*}&lt;/script&gt;

&lt;p&gt;这个公式没有目标(需要)，但我们可以加上最小化，例如，节点或链接的数量，总成本等，这取决于特定的网络必需品。方程式(1)、(2)和(3)是流守恒约束，负责从源到目的地的路由并且确保找到一条从u到v的路径。更特别，Eq(1)确保如果fi放在节点u和fj没有放在节点u上，从u出站的流量的总和等于1。Eq(2)保证fj放置在节点v上而fi没有放置在节点v上，则v的传入流量之和为1。Eq(3)保证如果fi和fj不在节点v上，则v的输入流量和v的输出流量相等。Eq(4)保证每个所需的VNF f必须放置在网络中的一个节点上。Eq.(5)保证每个链路上分配的总带宽不超过其最大容量，用c(u,v)表示。Eq(6)保证每个节点分配的总处理能力不超过其最大处理能力，其中，$\eta (f)$表示f所需要的资源，而$\pi (n)$表示节点n的总可用资源。&lt;/p&gt;

&lt;p&gt;当$X^{f,r}&lt;em&gt;n$ 或 $Y&lt;/em&gt;{f_i,f_j,r}^{(u,v)$为输入时，上述INLP相应改变以解决TRR问题或VNFP问题。为了解决VRC问题，设置在R中已经提供了(一些)请求，这些请求已经被在节点上放置了所需的VNFs并选择了适当的路径。在此基础上，我们可以在方程式中1、2、3、4、5、6上运行INLP求解。也就是说，方程式1、2、3、4、5和6相当general。同样值得提及的是，方程式(1)、(2)、(3)、(4)、(5)、(6)解决了一般网络中基本的VPTR问题，不考虑QoS要求，如成本、时延、可用性、能量等。但是，我们可以将这个公式扩展到通过考虑不同网络架构下的QoS要求来解决VPTR问题。为简单起见，延迟感知和可用性感知的VPTR问题公式参见[16]，能量感知的VPTR问题公式参见[19]。此外，VPTR问题的公式并不是我们上面所说的唯一的，只要稍微改变问题的输入就会导致不同的公式。例如，假设给定网络中每个节点对之间的一组路径，则VPTR问题公式与方程式(1)，(2)，(3)不同，因为在这个场景中不存在多社区路由约束。然而，由于INLP具有指数运行时间，它不能在合理的时间内返回一个解，特别是当问题规模很大时，这就需要多项式运行时间近似算法或有效的启发式来解决这个问题。&lt;/p&gt;

&lt;h3 id=&quot;mainly-adopted-approaches&quot;&gt;Mainly Adopted Approaches&lt;/h3&gt;

&lt;p&gt;正如我们在本调查中总结的，处理NFV资源分配最常见的方法包括组合优化理论(如随机/LP舍入、原对偶近似)、深度强化学习、博弈论等。下面，我们将简要介绍具有代表性的方法及其描述：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Randomized/LP rounding：首先将求解问题作为一个整数线性规划公式，然后计算该整数线性规划松弛问题的最优分式解。然后，将LP的分式解整取为原始问题的整数解，使之与最优解保持一定距离。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Primal-Dual approximation：原对偶方法(或原对偶模式)是求解线性程序的另一种方法。该方法的基本思想是从对偶规划的一个可行解y开始，然后试图找到满足互补松弛条件的原始规划的一个可行解x。如果找不到这样一个x，我们就找不到一个更好的客观值y。然后，开始另一个迭代。同时构造了原始IP的近似解和对偶LP的可行解，并逐步改进。最后将近似解与对偶可行解进行比较，估计出近似比。&lt;/li&gt;
  &lt;li&gt;Markov Approximation：首先推导出一个组合问题的最优值的对数和exp逼近，从而得到一个可由时间可逆马尔科夫链实现的解。在这类马尔可夫链中，某些精心设计的马尔可夫链可以产生近似求解网络优化问题的分布式算法。&lt;/li&gt;
  &lt;li&gt;Local Search：局部搜索通过应用局部变化在候选解的空间(搜索空间)中从一个解移动到另一个解，直到找到一个被认为是最优的解或经过了一定的时间限制。&lt;/li&gt;
  &lt;li&gt;Alternating Direction Method of Multipliers (ADMM)：首先将目标和变量分离为两部分，然后对占其中一部分目标的一组变量进行交替优化，迭代达到最优。&lt;/li&gt;
  &lt;li&gt;Column Generation：它从问题的一小部分作为受限主问题(RMP)开始，然后通过分析该部分解决方案来发现问题的下一部分来解决该部分。在此之后，向模型中添加一个或多个变量，然后解析放大后的模型。这个过程重复进行，直到整个问题得到满意的解决方案。&lt;/li&gt;
  &lt;li&gt;Generalized Benders Decomposition (GBD)：在广义弯折分解(GBD)中，原问题被投影到第一阶段变量的空间中，并重新表述为一个包含无限个约束的对偶问题，然后将其松弛为一个包含这些约束的有限子集的下界问题。在将第一阶段变量固定为下界问题的解之后，原始问题就变成了上界问题，对于每一个场景，上界问题都可以自然地分解为更小的子问题。一类上界问题的解给出了目标函数最优值上的一个非递减上界，一类下界问题的解给出了一个非递增的下界。当上界和下界收敛时，得到原问题的一个最优解。&lt;/li&gt;
  &lt;li&gt;Deep Reinforcement Learning (DRL)：DRL是一种解决决策问题的方法，它结合了强化学习(RL)的思想和深度学习(DL)的结构。RL的本质是通过与环境的试错交互来学习。RL代理首先感知环境的状态，然后根据当前状态选择操作。到达新状态后，代理会收到与新状态相关联的奖励。获得的奖励会告诉特工所采取的行动是好是坏。代理的目的是寻找最优策略。策略是agent根据当前状态来决定下一步行动，从而使回报最大化的策略。DL在DRL中的作用是利用神经网络强大的表示能力来适应RL agent的策略，例如处理复杂动态环境中的问题。&lt;/li&gt;
  &lt;li&gt;Game theory：博弈论是研究竞争对手之间战略互动的理论模型。它通常用于解决在存在竞争、合作或冲突的情况下为每个玩家选择最优决策的问题。一个博弈模型通常由两个或两个以上的参与者、一组策略和效用函数组成。一般而言，独立做出决定的玩家可能是恶意的、合作的或自私的，而玩家的成功决策取决于他人的选择。在博弈论中，玩家轮流与其他对手竞争以最大化他们的收益，直到他们达到纳什均衡(NE)。NE是一种稳定状态，在这种状态下，在考虑了其他对手的选择后，没有玩家会有偏离自己选择的策略的动机。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通常，随机/LP舍入、原对偶和马尔可夫近似技术用于设计近似算法。局部搜索方法有助于加快寻找局部最优解的速度，但不能保证能找到全局最优解，因此它是一种启发式解。ADMM、列生成和GBD在实际应用中可以快速收敛到最优解，但理论上仍具有指数运行时间。DRL为解决组合优化问题(如NFV资源分配问题)提供了一个新的视角，但DRL具有不确定的收敛时间和较长的训练时间。博弈论提供了一个分布式的方式在NFV解决资源分配问题,但由于由于缺乏全球网络信息，实质上它不能解决资源配置问题NFV为了得到最优解，以及考虑更多的QoS参数如延迟和可用性。&lt;/p&gt;

&lt;h2 id=&quot;qos-models-in-nfv&quot;&gt;QoS Models in NFV&lt;/h2&gt;

&lt;p&gt;时延和可用性是NFV服务中两个重要的QoS参数，本文研究了一般情况下NFV中如何定量计算时延和可用性。此外，我们还提供了一个VNF位置可用性计算模型，该模型也可以在[16]中看到。其他的QoS模型将在第4节提到相应的文献时进行介绍，因为其简单性和与本节介绍的模型的相似性。&lt;/p&gt;

&lt;h3 id=&quot;delay-calculation-of-an-sfc&quot;&gt;Delay Calculation of an SFC&lt;/h3&gt;

&lt;p&gt;根据函数链的特点,有三种VNFs之间的依赖关系,即(1)non-ordered: VNFs之间没有依赖关系,(2)完全有序:有一个总依赖秩序VNF集,和(3)半序:VNFs的子集之间存在依赖关系。遍历时延的计算主要依赖于全有序场景和部分有序场景，因为实际中无序场景并不经常发生。下图显示了一个完全有序的SFC：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2020-10-21-thesis-reading-01/yang3-3017001-small.gif&quot; alt=&quot;yang3-3017001-small&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们假设一个SFC包含一组|F|个有序VNFs, f1, f2，…，它们需要被放置在网络中。假设|F| VNFs有一个完全依赖顺序，那么一个完全有序的SFC的遍历延迟计算如下:
&lt;script type=&quot;math/tex&quot;&gt;\begin{equation*} \sum _{f \in F, n \in \mathcal {N}} \Psi ^f_n+\sum _{l \in \mathcal {L}^s} d(l). \tag{7} \end{equation*}&lt;/script&gt;
其中$ \Psi ^f_n $表示函数f在节点n上的处理延迟，$ \mathcal {L}^s $表示连接这些放置的VNF的链路集，d(l)表示在链路l上传递延迟的流。&lt;/p&gt;

&lt;p&gt;然而，由于监控功能实际上只维护数据包而不更改数据包，这表明防火墙和监控功能并不相互依赖。从这个意义上讲,这两个函数可以工作在两种情况下,即(1)在SFC中，它们以任意顺序工作；(2)他们在SFC并行工作。(1),ingress-a-c-b-d-egress也是一个可行的的SFC选择。在case(2)中，防火墙与监控并行工作，如图3b所示。之后，防火墙和监控功能将各自处理过的数据包发送到负载均衡器。因此，负载均衡器只需要从防火墙中选择数据包并处理它们。因此，可能存在多条数据路由在部分有序链中从入口节点到出口节点进行遍历。因此，并行SFC的遍历时延等于最长时延路由，即该数据传递路由的节点时延和链路时延之和最大。例如，图3b中的SFC遍历时延等于路径ingress→a - c - d→egress，其时延为50+10+80+25+60=225 ms，小于图3a中的时延。很明显，与完全有序的延迟相比，部分有序的SFC可以缩短服务延迟，但这是以消耗更多链路带宽为代价的。因此，使用全有序SFC还是部分有序SFC，取决于网络预算和应用需求的权衡。&lt;/p&gt;

&lt;p&gt;从上面的例子中我们可以看到，给定一个必需的非有序链，就会存在多个可能的SFCs(顺序的或并行的)。我们把产生这种可能的SFCs的过程称为链组成问题。图3也称为SFC转发图。在本次调查中，我们假设在NFV中，将SFC转发图输入到资源分配问题中，因此我们没有解决链组成问题。&lt;/p&gt;

&lt;h3 id=&quot;nfv-resilience&quot;&gt;NFV Resilience&lt;/h3&gt;

&lt;p&gt;弹性是NFV的另一个重要的QoS参数，它定义了所提供的服务在面对失败时的生存水平。因为，一旦SFC的一个节点或一个链接出现故障，整个SFC就无法运作，所提供的服务就必须停止。解决这个问题的一个有效方法是提供冗余的SFCs，这些SFCs通常将请求的VNFs放置在不同的节点上以防止节点故障(称为node-disjoint)或选择不遍历同一链接的路径(称为link-disjoint)来克服链路故障。这样，服务通常由主SFC提供，当主SFC出现节点/链路故障时，备用SFC将被激活以工作。这种方法也被称为SFC保护。&lt;/p&gt;

&lt;p&gt;Hmaity等研究了三种情况下的SFC保护，即:(1)端到端保护:一个主SFC和一个备用SFC（节点和链路都是不相交的）;(2)链路保护;(3)节点保护。下图反映了在网络中放置3个VNFs的三种保护方案，其中红线表示主路径，蓝线表示备份路径&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2020-10-21-thesis-reading-01/yang4-3017001-small.gif&quot; alt=&quot;yang4-3017001-small&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然而，Hmaity等人提出的SFC保护方案没有考虑节点和链路的失效概率。例如，如果主SFC和备份SFC都包含故障概率较高的节点或链接，那么这种保护也不能保证可靠的服务。此外，在这种方法中，仅考虑k=2个SFCs的保护(即一个VNF副本)。但在实际应用中，为了提供更可靠的服务，我们有时需要提供k≥2个SFCs。为了解决这个问题，我们基于图4中提出的保护方案，提出了一个定量模型来计算VNF的布置可用性。与[30]类似，我们考虑节点和链接的可用性，以定量测量任何k≥1 VNF副本/备份的SFC保护的可靠性。更具体地说，系统的可用性是系统在整个服务时间内运行的时间所占的比例。网络组件j的可用性Aj可以计算为:
&lt;script type=&quot;math/tex&quot;&gt;\begin{equation*} A_{j}=\frac{MTTF}{MTTF+MTTR}, \tag{8} \end{equation*}&lt;/script&gt;
式中，MTTF表示平均故障时间，MTTR表示平均修复时间。网络中的节点表示服务器，而链路表示连接两个物理服务器的物理链路。它们的可用性等于其所有组件(例如，节点的硬盘和内存，链路的放大器和光纤)可用性的乘积。对于一个服务器n，设a (n)和p(n)分别表示其可用性值和故障概率，则有a (n)=1−p(n)。节点故障可能因服务器年龄、硬盘数量等不同而不同，它们可能是由硬件组件故障、软件bug、电源丢失事件等引起的。实际上，我们可以通过访问记录服务器生命周期中每个硬件组件修复/故障事件的详细日志来获得服务器的可用性值。描述服务器故障和统计计算节点可用性的细节可以在[32]，[33]和其中的论文中找到。参考[34]和其中的论文提供了数据中心中其他网络设备(如交换机)的故障统计。&lt;/p&gt;

&lt;p&gt;我们区分并分析了两种不同情况下的VNF放置可用性，即:(1)不受保护的SFC:只允许在网络中放置一个SFC;(2)受保护的SFC:网络中最多可以放置k≥2个SFCs。&lt;/p&gt;

&lt;p&gt;假设一个不受保护的SFC将VNFs放在w个节点n1, n2，…， nw，遍历m个连接l1, l2，…， lm，其可用性计算为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation*} \prod _{i=1}^w A_{n_i} \cdot \prod _{j=1}^m A_{l_j}, \tag{9} \end{equation*}&lt;/script&gt;

&lt;p&gt;其中$\prod &lt;em&gt;{i=1}^w A&lt;/em&gt;{n_i}$表示所有节点的可用性，$\prod &lt;em&gt;{j=1}^m A&lt;/em&gt;{l_j}$表示所有遍历链接的可用性&lt;/p&gt;

&lt;p&gt;在受保护的SFC中，我们强调它是由(最大)k个不受保护的SFCs组成。为便于澄清，我们进一步将受保护放置中k不受保护的SFC分别称为placement组$p_i$。我们用第一个放置组表示。因为不同的放置组可能将一个或多个VNFs放在相同的节点和/或遍历链接，我们将保护放置分为两种情况,即(1)完全保护SFC：k放置组的每一个都把VNF放置在不同的节点、遍历不同的链接和(2)部分保护SFC：至少两个放置组在相同的节点上放置一个或多个VNFs或遍历相同的链接。在完全保护的放置情况下，可用性可以计算为&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation*} 1-\prod _{i=1}^k(1-A_{\rho _i}). \tag{10} \end{equation*}&lt;/script&gt;

&lt;p&gt;式(10)表示k个SFCs的可用性等于至少有一个SFC能够正常工作(不失败)的概率。例如，在图5a中，节点和链接的可用性是相关联的，我们使用s和d来表示进入和出口节点。为了便于表达，它们的可用性总是1。SFC的s-a-b-d和s-c-g-d是完全保护的，因为它们不包含任何相同的链路或节点。因此，这两种SFCs的总可用性为:&lt;/p&gt;

&lt;p&gt;1−(1−0.9⋅0.99⋅0.8⋅0.85⋅0.95)⋅(1−0.95⋅0.98⋅0.75⋅0.99⋅0.88)≈0.8338&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2020-10-21-thesis-reading-01/yang5-3017001-small.gif&quot; alt=&quot;yang5-3017001-small&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2020-10-21-thesis-reading-01/yang6-3017001-small.gif&quot; alt=&quot;yang6-3017001-small&quot; /&gt;&lt;/p&gt;

&lt;p&gt;接下来，我们考虑一个一般的场景，其中至少有两个k放置组将相同的VNF放置在相同的节点上，或者遍历相同的链接。在这种情况下，Eq.(10)不能用于计算这种情况下的可用性，因为重叠节点或链接的可用性将被多次计算。为了修正这一点，我们使用新的operator∘。假设有m个不同节点n1,n2，…，nm，可利用度An1,An2，…，Anm。对于具有可用性和Anx的节点，∘可定义为:&lt;/p&gt;

&lt;p&gt;在此，连接可用性的∘计算可被类似地定义。&lt;/p&gt;

&lt;p&gt;让∐表示连续∘操作的不同,交换,关联和分配。因此，k个部分保护的SFCs的可用性现在可以表示为&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*} &amp;1-\coprod _{i=1}^{k} (1-A_{\rho _{i}}) \\ =&amp;1- (1-A_{\rho _{1}})\circ (1-A_{\rho _{2}}) \circ \cdots \circ (1-A_{\rho _{k}}) \\ =&amp;\sum _{i=1}^{k}A_{\rho _{i}}-\sum _{0&lt;i&lt;j\leq k} A_{\rho _{i}} \circ A_{\rho _{j}}+ \\ &amp;\sum _{ 0&lt;i&lt;j&lt;u \leq k}A_{\rho _{i}} \circ A_{\rho _{j}} \circ A_{\rho _{u}}+\cdots +(-1)^{k-1}\coprod _{i=1}^{k}A_{\rho _{i}}, \tag{12} \end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;式中$A_{p_i}$表示安置组的可用性，可由式(9)计算，以图5b为例。SFCs s-a-b-d和s-c-b-d部分受到保护，因为它们共同将VNF f2放在节点b上，并且它们也通过相同的链路(b,d)。因此，总可用性计算为&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2020-10-21-thesis-reading-01/image-20201023152536021.png&quot; alt=&quot;image-20201023152536021&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;resource-allocation-in-nfv&quot;&gt;Resource Allocation in NFV&lt;/h2&gt;

&lt;p&gt;在本节中，我们调查了有关根据不同QoS参数(如成本、延迟、可用性、能量)进行资源分配的文献。我们还调查了有关边缘云、在线和分布式供应方案的相关文献。在每个类别(分段)中，我们在第2.1节基于四个广义资源分配问题进一步调查了文献，它们是VPTR问题，VNFP问题，TRR问题和VRC问题。我们以讨论结束每个小节。&lt;/p&gt;

&lt;h3 id=&quot;cost-aware-resource-allocation&quot;&gt;Cost-Aware Resource Allocation&lt;/h3&gt;

&lt;p&gt;在本节中，我们调查了关于NFV中成本意识资源分配的文献。这是NFV中最基本和最基本的资源分配问题，其问题公式见第2.4节。&lt;/p&gt;

&lt;h4 id=&quot;vptr-problem&quot;&gt;VPTR Problem&lt;/h4&gt;

&lt;p&gt;Ma等人[35]研究了最小化最大链路负载的VPTR问题。通过简化为np-hard哈密顿循环问题[36]，证明了即使在非有序VNF依赖情况下，VPTR问题也是np hard的。Ma等人[37]随后提出了一种基于LFGL的最小最大路由算法来解决VPTR问题，并在支持sdn的环境中实现了该算法。在非有序VNF依赖的情况下，Cohen等人[38]提出了一种使用舍入技术的近最优逼近算法来解决VPTR问题，使系统总代价最小化。[38]中的系统总成本包括放置在节点n上的功能f的设置成本，以及客户端与获得服务的节点之间距离的总和。Ghaznavi等人[39]建议在多个节点上分配VNF请求的实例，以最小化链路负载比(或最大化吞吐量)。他们随后提出了一种局部搜索启发式算法，该算法采用了一种调整参数来平衡速度和精度之间的权衡，从而解决了VPTR问题。Spinnewyn等人[40]在VPTR问题中联合考虑了部分有序链和位置约束。他们首先将问题表示为一个基于扩展VNF树的ILP，并预先计算出满足优先级要求的SFCs。在此基础上，提出了一种基于贪心链选择和嵌入的启发式算法。&lt;/p&gt;

&lt;p&gt;Kuo等人[41]放宽/近似VPTR问题的直觉是，将VNFs放置在较短的路径上会消耗更少的链路带宽，但也可能减少VM的重用机会;重用更多的vm可能导致更长的路径，因此消耗更多的链路带宽。对于一个给定的请求，冯et al。[42]提出一个O(ϵ)近似算法在时间O(1 /ϵ)找到最低成本解决方案VPTR问题,在那里ϵ代表一个设置为近似比的可调参数。特别是，允许在每个请求的VNF对之间通过多条路径路由流量。Guo等[43]共同考虑了数据中心中的VPTR问题。他们提出了一个已知交通矩阵的随机逼近算法和未来的到达交通未知的在线竞争算法。但是，他们假设数据中心中的一个配置由一条流量路由路径和一个VNF布局解决方案组成，给出了一个(有限)组态作为其问题的输入，从而在一定程度上简化了问题。Hamann和Fischer[44]将VPTR问题表示为一个ILP，其中网络中每个节点对之间的路径(k的集合)是预先计算和已知的。&lt;/p&gt;

&lt;h4 id=&quot;vnfp-problem&quot;&gt;VNFP Problem&lt;/h4&gt;

&lt;p&gt;You和Li[45]通过二分图对VNF布局约束进行建模，并提出负载均衡的最大-最小启发式来解决VNFP问题。Ma等人[35]提出了一种精确的多项式时间算法来解决无阶VNF依赖情况下的VNFP问题，并证明了全阶和部分阶依赖情况下的VNFP问题是np hard的。在这两种情况下，分别提出了一种动态规划和一种有效的启发式方法来解 决VNFP问题。Pham等人[46]提出了一种基于采样的马尔可夫近似算法来联合最小化VNFP问题的运营和网络流量代价。Tomassilli等人[47]研究VNFP问题的目的是最小化服务一组请求的总成本。Tomassilli等[47]将该问题转化为击打割问题，提出了两种对数因子逼近算法。第一种是基于LP舍入的算法，第二种是贪婪算法。在[48]中，VNFP问题中考虑了请求工作负载的时变。Li等人[48]认为两种工作负荷具有高相关性，即两种工作负荷的峰谷频繁重合。从这个意义上说，时间间隔内的每个工作负载变量都对应于一系列值。他们提出了一个精确整数非线性规划(INLP)和一个由一个基于相关的贪婪算法组成的两阶段算法。他们进一步调整算法来解决VNFP问题。Basta等人[49]提出了三种优化模型，通过寻找数据中心位置和SDN、NFV移动网络功能的最佳位置，以最大限度地降低网络负载成本和数据中心资源成本。&lt;/p&gt;

&lt;h4 id=&quot;trr-problem&quot;&gt;TRR Problem&lt;/h4&gt;

&lt;p&gt;Wang等人[50]提出了一种分布式交替方向乘法器(ADMM)算法来解决多请求的负载均衡TRR问题，该算法具有固定的覆盖率。&lt;/p&gt;

&lt;p&gt;SFC约束意味着从源到目的地的路由必须遍历每个有序的VNF。Sallam等人[51]设计了一个多项式时间算法，通过一个辅助图来解决sfc约束的最短路径(SP)问题。最大流量(MF)中的sfc约束问题规定，每个流量在到达目的地之前都要按预先指定的顺序遍历一组网络函数。他们后来提出了一个ILP来解决如何放置VNFs，使有SFC约束的最大流量的值等于没有SFC约束的原始最大流量的值。在多播流量路由NFV (MTRR)问题,有一个源节点和多个目标节点,问题是要找到一个多播树从源到目的地,这样每一个从源到目的地的路径遍历需要SFC会。徐等[52]设计一个近似算法来解决MTRR问题减少到一个辅助无向图的Steiner树问题。&lt;/p&gt;

&lt;h4 id=&quot;vrc-problem&quot;&gt;VRC Problem&lt;/h4&gt;

&lt;p&gt;在[53]中，假设网络生命周期由几个时间间隔组成。在每个时间间隔，服务提供者需要为两种用户提供服务，一种是需要分配所需VNFs的新用户，另一种是将所请求的VNFs迁移到新位置的in-service用户。在此基础上，提出了一个求解VRC问题的精确的ILP公式，并首先通过列生成近似的ILP，然后设计了一种启发式算法来进一步加速求解。列生成利用这种思想只生成有可能改进目标函数[54]的变量。&lt;/p&gt;

&lt;h4 id=&quot;discussion&quot;&gt;Discussion&lt;/h4&gt;

&lt;p&gt;NFV中的代价感知资源分配问题是最基本的，因为它只考虑网络代价，问题是当仅满足(基本)链路和节点容量约束时，是否存在相应的解决方案。然而，即使在这种情况下，VPTR问题和它的所有变体在一般情况下仍然是NP-hard，这表明了问题的难度。到目前为止，还没有一种近似算法可以解决一般情况下的问题。尽管提出了一些近似算法(如[42]、[43])，但它们在某种程度上简化了问题输入或约束。因此，只有精确的ILP解和启发式方法被提出来解决这个问题。接下来，我们将在这个问题中加入更多的QoS约束，如延迟和可靠性。&lt;/p&gt;

&lt;h3 id=&quot;delay-aware-resource-allocation&quot;&gt;Delay-Aware Resource Allocation&lt;/h3&gt;

&lt;p&gt;在本小节中，我们将调查关于NFV中延迟感知资源分配的文献，其中基于第2.4节中基本的NFV资源分配问题公式，延迟被额外考虑进去。相关文献主要采用3.1节中提出并讨论的类似延迟模型。&lt;/p&gt;

&lt;h4 id=&quot;vptr-and-trr-problem&quot;&gt;VPTR and TRR Problem&lt;/h4&gt;

&lt;p&gt;Qu等人[55]考虑了VNF传输和处理延迟，并将VPTR问题表示为混合整数线性规划(MILP)。但是，他们假设两个物理节点之间的虚拟链路一次最多只能处理一个流量流。Zhang等[56]设计了一种基于adm的算法来解决延迟感知的VPTR问题。然而，他们在他们的问题中没有考虑节点的延迟。Li等人[57]通过利用分组排队模型解决了延迟感知的VPTR问题。Sun等人[28]提出并实现了一个框架，使(独立的)网络功能能够并行工作，这极大地提高了NFV在延迟方面的性能(如图3b所示)。通过复制具有m个连接复制图的原始图，Huin等人[58]在列生成(使用有限数量的配置)的帮助下提出了一个数学公式，该公式可以很好地扩展问题输入(例如，请求或节点的数量)。Allybokus等人[59]提出了一个精确的ILP和一个贪婪启发式来解决完全有序和部分有序SFCs的VPTR问题。但是，他们的解决方案只考虑了SFC中的一个简单路径。Li等[60]考虑了一个胖树数据中心拓扑，并研究了(1)服务链接整合，(2)pod分配，以及(3)在离线和在线情况下每个pod的机器分配问题。延迟问题也被考虑在内。因此，他们提出了有效的启发式来解决这些问题。&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;此外，[61]和[62]设计了一种基于分层图的启发式算法来解决延迟感知TRR问题。一般的想法是，首先通过创建原始图的&lt;/td&gt;
      &lt;td&gt;F&lt;/td&gt;
      &lt;td&gt;副本来构造一个多层图，其中&lt;/td&gt;
      &lt;td&gt;F&lt;/td&gt;
      &lt;td&gt;表示请求的VNFs的数量。创建层间链接是为了连接不同层中的相同节点，创建层间节点是为了表示每一层中可能承载每个VNF的位置。该算法通过分配链路时延权值，找到从第1层的入口节点到&lt;/td&gt;
      &lt;td&gt;F&lt;/td&gt;
      &lt;td&gt;层的出口节点的最短路径。Xie等人[63]研究了NFV中存在多个源节点和目标节点的延迟感知多源组播路由问题。Xie等人[63]提出了一种基于最小生成树的启发式算法，该算法总是试图找到公共链接，以便部署的SFC能够被更多的请求(用户)共享。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;vnfp-problem-1&quot;&gt;VNFP Problem&lt;/h4&gt;

&lt;p&gt;Agarwal等人[65]将VNF布局和CPU分配问题制定为一个非凸优化模型，并将该问题划分为两个子问题。然后，他们提出了一种有效的启发式来解决延迟感知的VNFP问题，并设计了一个多项式时间来解决CPU分配问题，将其简化为KKT条件。&lt;/p&gt;

&lt;p&gt;在[66]中，假设一个请求r的数据包以泊松流的形式随机到达，具有一定的到达率。Zhang等人[66]进一步将每个请求建模为一个开放的Jackson网络。它们将多个请求流合并为一个服务实例作为一个流，并将每个服务实例建模为一个M/M/1队列。随后，他们进一步设计了一个二次逼近算法来解决延迟感知的VNFP问题。&lt;/p&gt;

&lt;h4 id=&quot;discussion-1&quot;&gt;Discussion&lt;/h4&gt;

&lt;p&gt;当再考虑SFC延迟约束时，我们看到VPTR问题及其变量比4.1节中更难解决。此外，一些文献通常采用排队理论同时考虑排队延迟和处理延迟来解决VPTR问题。然而，排队理论通常假设流量到达率遵循泊松过程，节点处理时间遵循指数分布，但在实践中并不总是这样(例如，突发流量)。&lt;/p&gt;

&lt;h3 id=&quot;availabilityresilience-aware-resource-allocation&quot;&gt;Availability/Resilience-Aware Resource Allocation&lt;/h3&gt;

&lt;p&gt;在本小节中，我们将调查有关NFV中可用性感知的资源分配的文献，其中，根据第2.4节中基本的NFV资源分配问题公式，可用性或弹性被额外考虑。相关文献采用了类似或不同的可用性模型，我们将在第3.2节中演示它。&lt;/p&gt;

&lt;h4 id=&quot;vptr-problem-1&quot;&gt;VPTR Problem&lt;/h4&gt;

&lt;p&gt;Beck等人[67]提出了一种可存活的VNF布局的递归启发式，以保证端到端的VNF保护。Han等人[68]探讨了单个VNF在故障管理(如故障检测和自动恢复)或状态管理方面的弹性方面。他们还讨论了针对这些方面的现有解决方案。Herker等人[69]阐述了如何计算数据中心拓扑中的VNF布局可用性。它们还对如何放置VNFs及其备份以满足请求的可用性提供了有效的启发。Fan等[70]考虑在给定主SFC的情况下，如何计算一个备用SFC，从而满足总体可用性。但是，考虑的可用性模型忽略了整个SFC的全局信息，不够精确。Ding等人[71]制定了在最多允许一个备份链接时如何计算VNF布局可用性。在[70]的基础上，考虑到主SFCs已经被放置在网络中，他们[71]提出了一种启发式方法来计算各自的备份SFCs的最小代价，从而满足每个请求的总可用性。&lt;/p&gt;

&lt;p&gt;在[74]中，假设给定了一组具有函数失效概率和若干服务器的函数。他们处理如何找到一个赋值，使恢复所有错误函数的概率最大化，或使操作函数的期望数量最大化。在恢复中，每个失败的功能可以匹配到一台服务器，并且每个服务器最多可以匹配到一个失败的功能。他们证明了这两个问题在一般情况下是np hard的，并发展启发式依赖于图理论模型来寻找一个有效分配的性质。在[75]中，作者假设对于n台备份机器，在每台机器上最多可以备份c函数。假设最多t个函数同时失败，证明了t=1,2,3,4时能够完全恢复的函数的最大数目。但是，他们假设在某些函数发生故障时，机器最多只能恢复它实现的一个函数，这在一定程度上简化了问题。此外，在[76]中，可靠性水平直接反映为每个请求的VNF的副本数。&lt;/p&gt;

&lt;h4 id=&quot;vnfp-problem-2&quot;&gt;VNFP Problem&lt;/h4&gt;

&lt;p&gt;在[77]中，假设总共有U种失败场景，每个失败场景i的失败概率为$p_i$。他们将VNFP问题表示为一个ILP，然后将其分解为一个主问题和一个子问题。通过利用广义弯曲分解(GBD)，主问题和子问题在不同的分区上被迭代地解决。在每次迭代中，它们生成原始问题目标值的上界和下界。当上界和下界满足终止条件时，迭代过程停止。Vizarreta等人[78]通过提出一个ILP和一个启发式来考虑端到端延迟和服务链接可用性，解决了QoS VNF布局问题。然而，在他们的工作中并没有考虑VNF保护案例中的VNF位置可用性。&lt;/p&gt;

&lt;h4 id=&quot;trr-problem-1&quot;&gt;TRR Problem&lt;/h4&gt;

&lt;p&gt;Yu等人[79]将可靠性级别定义为在任意单次服务故障期间，最多$r_j$带宽丢失，这意味着使用多条路径在每个相邻的VNF对之间遍历数据。假设VNF已经被放置在网络中，并且给定了节点对之间的一组路径，Yu等人[79]研究了如何在每个相邻的VNF对之间找到一个可行路由路径的子集，从而满足可靠性要求。他们提出了一个基于原对偶理论的全多项式时间逼近方案(FPTAS)来解决这个问题。&lt;/p&gt;

&lt;h4 id=&quot;discussion-2&quot;&gt;Discussion&lt;/h4&gt;

&lt;p&gt;不同的文献对可靠性的定义不同，这导致了不同的问题输入和约束以及解决方案。有些文献只考虑节点/链接备份，有些文献还考虑了节点和链接的可用性。当k≥2个不相交的SFCs被提供时，服务可以同时从k−1节点和/或链路故障中恢复。但是，这种方法忽略了节点/链路的失效概率，其代价很高。相反，SFC的可用性计算更精确，可以定量地衡量NFV服务的可靠性，即使节点和链路的可用性值不容易实现。&lt;/p&gt;

&lt;h3 id=&quot;energy-efficient-resource-allocation&quot;&gt;Energy-Efficient Resource Allocation&lt;/h3&gt;

&lt;p&gt;在本节中，我们将调查有关NFV中节能资源分配的文献。我们将首先介绍主要的能源消耗模型，然后调查该领域的相关文献。&lt;/p&gt;

&lt;h4 id=&quot;vptr-problem-2&quot;&gt;VPTR Problem&lt;/h4&gt;

&lt;p&gt;通过M/M/C排队模型，Kar等人[80]提出了一个精确的ILP和一个有效的启发式来解决能量感知的VPTR问题。虽然这项工作只针对动态的单个请求，但Jang等人[19]通过提出INLP和基于轮询的启发式来处理如何最小化多个请求的能源消耗。Huang等人[81]在混合NFV网络中解决了VNF布局和路由问题，目标是使已接纳流量的利润减去能量成本和路由成本最大化。一个混合的NFV网络建模一个硬件网络功能和虚拟网络功能共存的网络。为了解决这个问题，他们提出了一种基于马尔可夫近似的有界近似比算法。Eramo等人[82]首先针对VPTR问题，其目标是在峰值流量时最大化网络中可处理的数据量。随后，他们研究了如何合并VNFs和关闭未使用的服务器，以使总操作成本(能源消耗+收入损失)最小化。他们提出了一个精确的ILP和一个有效的启发式来解决每个问题。&lt;/p&gt;

&lt;h4 id=&quot;vrc-problem-1&quot;&gt;VRC Problem&lt;/h4&gt;

&lt;p&gt;Eramo等人[83]给出了能量感知的VRC问题，并证明了它是np hard问题。在这里，需要将一些VNFs从“源”服务器迁移到“目的地”服务器，以便关闭额外的空闲服务器以节省能源。因此，总能耗包括(1)整合能耗:它描述了在“目标”服务器上执行VNFs的能耗;(2)迁移能耗，它表示保持“源”服务器处于活动状态的能耗。随后，他们提出了一种借助多阶段图的启发式方法，它可以表示不同时间间隔内的能源消耗。在[84]中，假设有三个组件是耗能的，即(1)服务器;(2)网络路由器节点，其中一些节点与服务器相连;(3)链路。当没有通信量穿越网络节点和链接时，可以关闭它们以节省能源。此外,他们的模型,所请求的资源的能力VNF f变化的范围:[η(f)ˆ−Δ,η(f)ˆ+Δ],在那里η(f)ˆ表明f的平均处理能力(请求的资源)和Δ意味着最大偏差。他们第一次独立提出一个公式,解决了Γ健壮性VPTR问题,那里的交通需求是允许在一个给定的绑定Γ偏离。随后，他们提出了一个快速的变量固定启发式，利用来自问题的线性松弛的结构信息。&lt;/p&gt;

&lt;h4 id=&quot;discussion-3&quot;&gt;Discussion&lt;/h4&gt;

&lt;p&gt;能源消耗可以看作是一种“成本”，但根据方程式16、17，它不是线性的。由于这个原因，NFV中成本感知资源分配的相应解决方案不能直接应用于此。此外，由于能量约束的非线性和非凸性，利用上文第2.5节中提到的方法很难设计近似算法。因此，采用列生成、GBD或ADMM方法的算法可以有效地基于精确解进行工作。&lt;/p&gt;

&lt;h3 id=&quot;multi-objective-resource-allocation-in-edge-cloud&quot;&gt;(Multi-Objective) Resource Allocation in Edge Cloud&lt;/h3&gt;

&lt;p&gt;移动边缘计算(Mobile Edge Computing, MEC)[85]的概念是通过在网络边缘(也称为边缘云)上安装小型资源有限的云基础设施，使计算资源更接近终端用户，从而为终端用户提供延迟保障服务。将NFV应用到MEC中，不仅可以缩短终端用户的服务延迟，而且服务提供商也将受益于更低的支出和更高的效率。在此上下文中，用户请求的服务由需要放在边缘或公共云上的VNFs序列组成。在这个小节中，我们将调查关于边缘云中的NFV资源分配的文献。&lt;/p&gt;

&lt;h4 id=&quot;vptr-problem-3&quot;&gt;VPTR Problem&lt;/h4&gt;

&lt;p&gt;在[86]中，Riggio等人解决了无线接入网中的无线VNF布局和流量路由问题。与传统的有线网络相比，VNF和节点都有一个额外的要求，称为无线电资源(但也是附加的，类似于成本)。Riggio等人[86]为这个问题提出了一个ILP和一个启发式。Wang等[87]研究了VPTR问题，共同最小化链路负载比和节点CPU利用率的资源利用率。他们提出了一种基于round- based逼近算法来解决这个问题。Yang等人[88]提出了一种近似算法，通过考虑完全有序和部分有序的SFCs来解决边缘云中的VPTR问题。在[88]中提出的近似算法利用随机舍入技术，并假设每个节点对之间的路径是已知的/给定的。&lt;/p&gt;

&lt;p&gt;此外，还有一些针对多目标VPTR问题的研究(如联合优化成本、时延、可靠性等)。然而，由于VPTR问题本身具有np hard性，多目标VPTR问题更难解，设计了直接启发式[89]、[90]、[91]来解决它。&lt;/p&gt;

&lt;h4 id=&quot;vnfp-problem-3&quot;&gt;VNFP Problem&lt;/h4&gt;

&lt;p&gt;Cziva等人[92]处理网络边缘的VNFP问题以最小化所有用户到各自VNFs的预期总延迟。他们进一步利用最优停止理论，通过考虑迁移成本和随机路径延迟来确定何时重新评估最优布局问题。但是，他们假设只有一个VNF就足以为一个用户提供服务，而不是一系列VNFs。Yang等人[93]研究了如何将启用nfv的服务放置在最小数量的边缘节点上，并寻找从接入点到被请求服务所在节点的路由，以满足延迟要求。他们提出了一种启发式的增量分配机制来解决这个问题。Nam等人[94]提供了一种聚类NFV服务链接(cNSC)方案，该方案应用随机模型计算根据VNFs的流行度放置的最优集群数量，以最小化MEC服务的端到端时间。Jemaa等[95]将对端云的请求建模为M/M/1队列，对公有云的请求建模为M/G1/∞队列。随后，他们提出了一个精确的ILP来解决如何在不违反延迟约束的情况下将VNFs放置在边缘云中。&lt;/p&gt;

&lt;p&gt;Song等[96]通过考虑用户的移动性来研究5G边缘网络中的VNFP问题。他们[96]首先提出了基于用户上下文地理信息的用户分组模型，然后定义(并计算最优的数量)簇以最小化网络服务的端到端延迟。随后，提出了一种将VNFs分配给边缘网络中的集群的图划分算法，以最小化用户在集群之间的移动，并优化用户因VNF迁移而丢失的数据速率。&lt;/p&gt;

&lt;h4 id=&quot;discussion-4&quot;&gt;Discussion&lt;/h4&gt;

&lt;p&gt;在边缘云环境下，VPTR问题还需要考虑用户的位置，同时还要考虑用户与边缘服务器之间的无线传输和边缘服务器与云服务器之间的有线链路传输。从这个意义上说，同时考虑多个QoS参数会使这个问题难以解决，但值得我们在以后的工作中进一步探索。&lt;/p&gt;

&lt;h3 id=&quot;on-line-provisioning-for-nfv&quot;&gt;On-Line Provisioning for NFV&lt;/h3&gt;

&lt;p&gt;在在线配置中，未来流量矩阵是未知的。如果g(x)/OPT≤β，则在线策略x是不具有竞争力的，其中g(x)为策略x的实现成本，OPT为最优解决方案的成本。在这个小节中，我们将集中调查关于在线NFV资源分配的文献。&lt;/p&gt;

&lt;h4 id=&quot;prediction-based-online-scheduling&quot;&gt;Prediction-Based Online Scheduling&lt;/h4&gt;

&lt;p&gt;Mijumbi等人[97]通过利用服务链的拓扑信息，提出了一种基于图神经网络的算法，以预测每个VNF组件未来的资源需求。Bu等人[98]利用自回归(AR)预测VNF的长期和短期流行度，即VNF被要求的频率。在预测的基础上，设计了一种动态的网络功能部署机制，在大量请求之前预先部署合适的功能，并根据当前网络状态实时部署一些新请求的功能。&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;在[99]、[100]中，假设有若干个&lt;/td&gt;
      &lt;td&gt;T&lt;/td&gt;
      &lt;td&gt;时间间隔，一个流量需求$r_i$到达时间$t_i$，持续到$z_i$时间间隔。交通需求的交通率随时间而变化。VNF容量应该不小于流量需求的速率，否则应该启动新的VNF实例，以满足请求的流量速率。Zhang等人[99]通过使用在线梯度下降(OGD)预测算法来预测未来的VNF需求，解决了代价敏感的VNFP问题。Fei等人[100]使用一种名为follow-the-regularized-leader (FTRL)的高效在线学习方法，与最佳静态预测策略相比，有界理性(原文是regret，不知道该怎么翻译)地预测即将到来的流。在预测算法的基础上，他们进一步设计了近似算法来放置新的需要的VNFs和在它们之间路由流。结合预测和近似算法，提出了一种在线竞争算法来解决代价敏感的VNFP问题。然而，正如我们前面提到的，现实中的流量是动态的、不规则的，这是不容易预测的。在这个意义上，基于预测的在线调度算法在实践中可能不是很有效。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;regularization-based-online-scheduling&quot;&gt;Regularization-Based Online Scheduling&lt;/h4&gt;

&lt;h2 id=&quot;emerging-topics-and-future-works&quot;&gt;Emerging Topics and Future Works&lt;/h2&gt;

&lt;p&gt;关于NFV的资源分配，仍然有一些开放的领域或有趣的主题需要深入考虑：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2020-10-21-thesis-reading-01/yang.t1-3017001-small.gif&quot; alt=&quot;yang.t1-3017001-small&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;machine-learning-based-approaches&quot;&gt;Machine Learning-Based Approaches&lt;/h3&gt;

</description>
        <pubDate>Sat, 24 Oct 2020 12:51:40 +0800</pubDate>
        <link>http://2bebetter.github.io/thesis/2020/10/24/thesis-reading-01/</link>
        <guid isPermaLink="true">http://2bebetter.github.io/thesis/2020/10/24/thesis-reading-01/</guid>
        
        
        <category>thesis</category>
        
      </item>
    
      <item>
        <title>Your first blog</title>
        <description>&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#first-post使用githubio和jekyll搭建个人博客&quot; id=&quot;markdown-toc-first-post使用githubio和jekyll搭建个人博客&quot;&gt;First Post——使用github.io和jekyll搭建个人博客&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#配置环境&quot; id=&quot;markdown-toc-配置环境&quot;&gt;配置环境&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#jekyll&quot; id=&quot;markdown-toc-jekyll&quot;&gt;jekyll&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#githubio&quot; id=&quot;markdown-toc-githubio&quot;&gt;github.io&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#create-a-repository&quot; id=&quot;markdown-toc-create-a-repository&quot;&gt;Create a repository&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#clone-the-repository&quot; id=&quot;markdown-toc-clone-the-repository&quot;&gt;Clone the repository&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#hello-world&quot; id=&quot;markdown-toc-hello-world&quot;&gt;Hello world&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#personal-blog&quot; id=&quot;markdown-toc-personal-blog&quot;&gt;Personal Blog&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#run-the-first-blog&quot; id=&quot;markdown-toc-run-the-first-blog&quot;&gt;Run the first blog&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#markdown编译器&quot; id=&quot;markdown-toc-markdown编译器&quot;&gt;markdown编译器&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#配置github&quot; id=&quot;markdown-toc-配置github&quot;&gt;配置github&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#插入图片&quot; id=&quot;markdown-toc-插入图片&quot;&gt;插入图片&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#数学公式&quot; id=&quot;markdown-toc-数学公式&quot;&gt;数学公式&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;first-post使用githubio和jekyll搭建个人博客&quot;&gt;First Post——使用github.io和jekyll搭建个人博客&lt;/h1&gt;

&lt;p&gt;由于最近可能会阅读一些论文，因此决定搭建一个个人博客用以记录论文阅读过程中可能会产生的笔记，而CSDN的博客我个人不太喜欢，又由于自己的囊中羞涩，最后决定使用github.io结合jekyll搭建一个博客。&lt;/p&gt;

&lt;h2 id=&quot;配置环境&quot;&gt;配置环境&lt;/h2&gt;

&lt;h3 id=&quot;jekyll&quot;&gt;jekyll&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;install&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因为win10内嵌了linux子系统，而使用linux安装jekyll个人觉得要比windows系统相对来说更为容易，因此决定在该linux子系统内配置环境。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt install ruby jekyll&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ol&gt;
  &lt;li&gt;new project&lt;/li&gt;
&lt;/ol&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;jekyll new helloworld

&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;helloworld

jekyll serve&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;githubio&quot;&gt;github.io&lt;/h3&gt;

&lt;h4 id=&quot;create-a-repository&quot;&gt;Create a repository&lt;/h4&gt;

&lt;p&gt;在GitHub中创建一个名为username.github.io的新仓库，其中username是你在GitHub上的用户名&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2020-10-21-personal-blog/image-20201020190937302.png&quot; alt=&quot;image-20201020190937302&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;clone-the-repository&quot;&gt;Clone the repository&lt;/h4&gt;

&lt;p&gt;转到要存储项目的文件夹，然后克隆这个仓库：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git clone https://github.com/username/username.github.io&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;hello-world&quot;&gt;Hello world&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;username.github.io

&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Hello, world&#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; index.html&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;personal-blog&quot;&gt;Personal Blog&lt;/h3&gt;

&lt;h4 id=&quot;run-the-first-blog&quot;&gt;Run the first blog&lt;/h4&gt;

&lt;p&gt;目前有很多的jekyll主题和模板，在这里提供一个网站&lt;a href=&quot;http://jekyllthemes.org/&quot;&gt;jekyll themes&lt;/a&gt;和一个教程：&lt;a href=&quot;https://github.com/Huxpro/huxpro.github.io/blob/master/_doc/README.zh.md&quot;&gt;说明文档&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;我个人选择了&lt;a href=&quot;http://jekyllthemes.org/themes/monos/&quot;&gt;monos&lt;/a&gt;这个主题，下载该主题后解压到你的项目文件夹下，运行之后会出现一些依赖不存在的情况，只需要按照它所提示的名称和版本安装即可&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;username:/jekyll-theme-monos-master&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;jekyll-theme-monos-master

username:/jekyll-theme-monos-master&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jekyll serve

Traceback &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;most recent call last:

  10: from /usr/bin/jekyll:7:in &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&amp;lt;main&amp;gt;&lt;span class=&quot;s1&quot;&gt;&#39;

  9: from /usr/lib/ruby/vendor_ruby/jekyll/plugin_manager.rb:33:in `require_from_bundler&#39;&lt;/span&gt;

  8: from /usr/local/lib/site_ruby/2.5.0/bundler.rb:149:in &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;setup&lt;span class=&quot;s1&quot;&gt;&#39;

  7: from /usr/local/lib/site_ruby/2.5.0/bundler/runtime.rb:20:in `setup&#39;&lt;/span&gt;

  6: from /usr/local/lib/site_ruby/2.5.0/bundler/runtime.rb:101:in &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;block &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;definition_method&lt;span class=&quot;s1&quot;&gt;&#39;

  5: from /usr/local/lib/site_ruby/2.5.0/bundler/definition.rb:226:in `requested_specs&#39;&lt;/span&gt;

  4: from /usr/local/lib/site_ruby/2.5.0/bundler/definition.rb:237:in &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;specs_for&lt;span class=&quot;s1&quot;&gt;&#39;

  3: from /usr/local/lib/site_ruby/2.5.0/bundler/definition.rb:170:in `specs&#39;&lt;/span&gt;

  2: from /usr/local/lib/site_ruby/2.5.0/bundler/spec_set.rb:80:in &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;materialize&lt;span class=&quot;s1&quot;&gt;&#39;

  1: from /usr/local/lib/site_ruby/2.5.0/bundler/spec_set.rb:80:in `map!&#39;&lt;/span&gt;

/usr/local/lib/site_ruby/2.5.0/bundler/spec_set.rb:86:in &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;block &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;materialize&lt;span class=&quot;s1&quot;&gt;&#39;: Could not find public_suffix-4.0.3 in any of the sources (Bundler::GemNotFound)

username:/jekyll-theme-monos-master$ sudo gem install bundler:1.17.2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;安装过程中可能会出现如下的错误，安装ruby-dev&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;username:/jekyll-theme-monos-master&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;gem install eventmachine &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; 1.2.7

Building native extensions. This could take a &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;...               

ERROR: Error installing eventmachine:

  ERROR: Failed to build gem native extension.

current directory: /var/lib/gems/2.5.0/gems/eventmachine-1.2.7/ext

/usr/bin/ruby2.5 &lt;span class=&quot;nt&quot;&gt;-I&lt;/span&gt; /usr/local/lib/site_ruby/2.5.0 &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; ./siteconf20201020-5764-1v6qrrl.rb extconf.rb  

mkmf.rb can&lt;span class=&quot;s1&quot;&gt;&#39;t find header files for ruby at /usr/lib/ruby/include/ruby.h

​    extconf failed, exit code 1

Gem files will remain installed in /var/lib/gems/2.5.0/gems/eventmachine-1.2.7 for inspection.   

Results logged to /var/lib/gems/2.5.0/extensions/x86_64-linux/2.5.0/eventmachine-1.2.7/gem_make.out 

username:/jekyll-theme-monos-master$ sudo apt install ruby-dev&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;markdown编译器&quot;&gt;markdown编译器&lt;/h4&gt;

&lt;p&gt;我的第一篇博客如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2020-10-21-personal-blog/image-20201021092055720.png&quot; alt=&quot;image-20201021092055720&quot; /&gt;&lt;/p&gt;

&lt;p&gt;感觉样式被解析的十分奇怪，这是因为jekyll的markdown语法和github，或简书上的markdown语法很不一样，比如代码高亮部分只能用以下形式:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2020-10-21-personal-blog/image-20201021104402448.png&quot; alt=&quot;image-20201021104402448&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当我们查看配置文件时，发现&lt;code class=&quot;highlighter-rouge&quot;&gt;Jekyll&lt;/code&gt;使用的&lt;code class=&quot;highlighter-rouge&quot;&gt;markdown&lt;/code&gt;解析器是默认使用的&lt;code class=&quot;highlighter-rouge&quot;&gt;kramdown&lt;/code&gt;，我们可以将其修改为我们需要的markdown解析器，jekyll支持三种markdown解析器：kramdown,redcarpet,rdiscount，同时我们可以通过在&lt;strong&gt;&lt;em&gt;*_config.yml*&lt;/em&gt;&lt;/strong&gt;文件中修改&lt;code class=&quot;highlighter-rouge&quot;&gt;markdown: kramdown&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;kramdown:[]&lt;/code&gt;修改markdown解析器的默认设置。&lt;/p&gt;

&lt;p&gt;Github Pages在今年宣布开始使用Jekyll 3.0, 导致的变化有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;将只支持kramdown作为Markdown引擎&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将只支持Rouge作为Markdown代码语法高亮&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;大幅提升构建速度&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;不再支持Permalinks和Textile&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以之前的配置方法现在不再适用，我们需要对Jekyll的相应配置重新进行修改。&lt;/p&gt;

&lt;h4 id=&quot;配置github&quot;&gt;配置github&lt;/h4&gt;

&lt;p&gt;在你的github仓库中修改settings设置，&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2020-10-21-personal-blog/image-20201021101011843.png&quot; alt=&quot;image-20201021101011843&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当出现提示“Your site is ready to be published at http://2bebetter.github.io”时，配置成功。&lt;/p&gt;

&lt;h4 id=&quot;插入图片&quot;&gt;插入图片&lt;/h4&gt;

&lt;p&gt;我使用的markdown编辑器是typora，插入图片时非常方便，但是不能正确在github上显示，修改typora和配置文件如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;typora&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;偏好设置-&amp;gt;图像-&amp;gt;图像插入时，选择”复制到指定位置”并将地址设为 &lt;code class=&quot;highlighter-rouge&quot;&gt;../img/${filename}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2020-10-21-personal-blog/image-20201021103739381.png&quot; alt=&quot;image-20201021103739381&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;jekyll&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在每一篇post的开头配置行中加入&lt;code class=&quot;highlighter-rouge&quot;&gt;typora-root-url: ..&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这样插入图片的时候，就会自动在_post平级的img文件下面生成一个与post同名的文件夹并放入名称类似&lt;code class=&quot;highlighter-rouge&quot;&gt;../img/in-post/post_name/picture_name.png&lt;/code&gt;的图片,通过&lt;code class=&quot;highlighter-rouge&quot;&gt;/img/post_name/picture_name.png&lt;/code&gt;引用图片的时候typora会去找&lt;code class=&quot;highlighter-rouge&quot;&gt;../img/post_name/picture_name.png&lt;/code&gt; 能够预览图片，在github pages时&lt;code class=&quot;highlighter-rouge&quot;&gt;typora-root-url: ..&lt;/code&gt; 无效，找的还是&lt;code class=&quot;highlighter-rouge&quot;&gt;/img/post_name/picture_name.png&lt;/code&gt;，能够正确显示图片。&lt;/p&gt;

&lt;h4 id=&quot;目录&quot;&gt;目录&lt;/h4&gt;

&lt;p&gt;plugin：&lt;a href=&quot;https://github.com/jossets/jekyll-toc&quot;&gt;jossets/jekyll-toc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这种方法可以兼容github-page：&lt;/p&gt;

&lt;p&gt;&lt;em&gt;A GitHub Pages compatible Table of Contents generator without a plugin or JavaScript :octocat: https://pure-liquid.allejo.org/&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;使用方法：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;下载最新的&lt;a href=&quot;https://github.com/jossets/jekyll-toc/blob/master/_includes/toc.html&quot;&gt;toc.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;将该文件拖进_includes文件夹下&lt;/li&gt;
  &lt;li&gt;在模板布局页面中&lt;code class=&quot;highlighter-rouge&quot;&gt;{\{ content \}}&lt;/code&gt;前加入：&lt;code class=&quot;highlighter-rouge&quot;&gt;\{\% include toc.html html=content \%\}&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;数学公式&quot;&gt;数学公式&lt;/h4&gt;

&lt;p&gt;使用latex编写数学公式是十分方便的，但是markdown本身并不支持latex公式，因此需要一些拓展，或者使用Typora编辑器自带的latex公式编辑。&lt;/p&gt;

&lt;p&gt;虽然jekyll并不支持latex，但是可以通过工具来实现，是一个开源的基于 Ajax 的数学公式显示的解决方案，结合多种先进的Web技术，支持主流的浏览器。需要把下面的JS调用代码以及配置插入到你Jekyll博客的header文件中：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-html&quot; data-lang=&quot;html&quot;&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;script &lt;/span&gt;&lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text/x-mathjax-config&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;MathJax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Hub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;tex2jax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;skipTags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;script&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;noscript&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;style&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;textarea&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;pre&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;inlineMath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;$&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;$&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;script &lt;/span&gt;&lt;span class=&quot;na&quot;&gt;src=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text/javascript&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
</description>
        <pubDate>Wed, 21 Oct 2020 10:21:40 +0800</pubDate>
        <link>http://2bebetter.github.io/jekyll/2020/10/21/personal-blog/</link>
        <guid isPermaLink="true">http://2bebetter.github.io/jekyll/2020/10/21/personal-blog/</guid>
        
        
        <category>jekyll</category>
        
      </item>
    
  </channel>
</rss>
